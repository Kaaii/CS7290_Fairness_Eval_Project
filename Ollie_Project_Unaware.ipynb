{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from torch import nn\n",
    "from pyro.nn import PyroModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "exo_dist = {\n",
    "    'Nr': dist.Bernoulli(torch.tensor(0.7)),\n",
    "    'Ns': dist.Bernoulli(torch.tensor(0.35)),\n",
    "    'Na': dist.Normal(torch.tensor(0.), torch.tensor(1.))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    exo_dist = {\n",
    "        'Nr': dist.Bernoulli(torch.tensor(0.7)),\n",
    "        'Ns': dist.Bernoulli(torch.tensor(0.35)),\n",
    "        'Na': dist.Normal(torch.tensor(0.), torch.tensor(1.))\n",
    "    }\n",
    "    # sample from bernoulli 0 or 1, 0 at 70% freq (made up)\n",
    "    R = pyro.sample(\"R\", exo_dist['Nr'])\n",
    "    S = pyro.sample(\"S\", exo_dist['Ns'])\n",
    "    \n",
    "    # random gaussian dist for ability \n",
    "    A = pyro.sample(\"A\", exo_dist['Na'])\n",
    "    \n",
    "    \n",
    "    G = pyro.sample(\"G\", dist.Normal(A + 2.1 * R + 3.3 * S, 0.5))\n",
    "    \n",
    "    L = pyro.sample(\"L\", dist.Normal(A + 5.8*R + 0.7*S, 0.1))\n",
    "    \n",
    "    F = pyro.sample(\"F\", dist.Normal(A + 2.3*R + 1.*S, 0.3))\n",
    "\n",
    "trace_handler = pyro.poutine.trace(model)\n",
    "samples = pd.DataFrame(columns=['R', 'S', 'A', 'G', 'L', 'F', 'p'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unaware Model\n",
    "\n",
    "This model uses only G and L to predict FYA. It is indirectly biased because R/S affect G and L, and also affect F."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "      <th>S</th>\n",
       "      <th>A</th>\n",
       "      <th>G</th>\n",
       "      <th>L</th>\n",
       "      <th>F</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(0.0263)</td>\n",
       "      <td>tensor(1.4554)</td>\n",
       "      <td>tensor(5.6359)</td>\n",
       "      <td>tensor(2.4945)</td>\n",
       "      <td>tensor(0.0435)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(0.7094)</td>\n",
       "      <td>tensor(3.0938)</td>\n",
       "      <td>tensor(6.4882)</td>\n",
       "      <td>tensor(2.9650)</td>\n",
       "      <td>tensor(0.4915)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(1.6020)</td>\n",
       "      <td>tensor(1.7183)</td>\n",
       "      <td>tensor(1.5369)</td>\n",
       "      <td>tensor(1.3702)</td>\n",
       "      <td>tensor(0.0533)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(2.2869)</td>\n",
       "      <td>tensor(8.0049)</td>\n",
       "      <td>tensor(8.8084)</td>\n",
       "      <td>tensor(5.8834)</td>\n",
       "      <td>tensor(0.0148)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(1.0806)</td>\n",
       "      <td>tensor(0.4785)</td>\n",
       "      <td>tensor(1.0816)</td>\n",
       "      <td>tensor(1.2844)</td>\n",
       "      <td>tensor(0.0706)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            R           S               A               G               L  \\\n",
       "0  tensor(1.)  tensor(0.)  tensor(0.0263)  tensor(1.4554)  tensor(5.6359)   \n",
       "1  tensor(1.)  tensor(0.)  tensor(0.7094)  tensor(3.0938)  tensor(6.4882)   \n",
       "2  tensor(0.)  tensor(0.)  tensor(1.6020)  tensor(1.7183)  tensor(1.5369)   \n",
       "3  tensor(1.)  tensor(1.)  tensor(2.2869)  tensor(8.0049)  tensor(8.8084)   \n",
       "4  tensor(0.)  tensor(0.)  tensor(1.0806)  tensor(0.4785)  tensor(1.0816)   \n",
       "\n",
       "                F               p  \n",
       "0  tensor(2.4945)  tensor(0.0435)  \n",
       "1  tensor(2.9650)  tensor(0.4915)  \n",
       "2  tensor(1.3702)  tensor(0.0533)  \n",
       "3  tensor(5.8834)  tensor(0.0148)  \n",
       "4  tensor(1.2844)  tensor(0.0706)  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unaware_sample= []\n",
    "for i in range(1000):\n",
    "    trace = trace_handler.get_trace()\n",
    "    R = trace.nodes['R']['value']\n",
    "    S = trace.nodes['S']['value']\n",
    "    A = trace.nodes['A']['value']\n",
    "    G = trace.nodes['G']['value']\n",
    "    L = trace.nodes['L']['value']\n",
    "    F = trace.nodes['F']['value']\n",
    "    # get prob of each combination\n",
    "    log_prob = trace.log_prob_sum()\n",
    "    p = np.exp(log_prob)\n",
    "    samples = samples.append({'R': R, 'S': S, 'A': A, 'G': G, 'L':L, 'F': F, 'p': p}, ignore_index=True)\n",
    "    unaware_sample.append(([G,L,F]))\n",
    "\n",
    "samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0010] loss: 1228.0948\n",
      "[iteration 0020] loss: 920.1564\n",
      "[iteration 0030] loss: 762.8047\n",
      "[iteration 0040] loss: 438.1056\n",
      "[iteration 0050] loss: 353.0892\n",
      "[iteration 0060] loss: 321.7837\n",
      "[iteration 0070] loss: 300.1779\n",
      "[iteration 0080] loss: 289.3389\n",
      "[iteration 0090] loss: 284.8181\n",
      "[iteration 0100] loss: 282.8357\n",
      "[iteration 0110] loss: 281.8677\n",
      "[iteration 0120] loss: 281.3944\n",
      "[iteration 0130] loss: 281.1844\n",
      "[iteration 0140] loss: 281.1036\n",
      "[iteration 0150] loss: 281.0769\n",
      "[iteration 0160] loss: 281.0694\n",
      "[iteration 0170] loss: 281.0674\n",
      "[iteration 0180] loss: 281.0671\n",
      "[iteration 0190] loss: 281.0671\n",
      "[iteration 0200] loss: 281.0671\n",
      "[iteration 0210] loss: 281.0671\n",
      "[iteration 0220] loss: 281.0671\n",
      "[iteration 0230] loss: 281.0671\n",
      "[iteration 0240] loss: 281.0671\n",
      "[iteration 0250] loss: 281.0671\n",
      "[iteration 0260] loss: 281.0671\n",
      "[iteration 0270] loss: 281.0671\n",
      "[iteration 0280] loss: 281.0671\n",
      "[iteration 0290] loss: 281.0671\n",
      "[iteration 0300] loss: 281.0671\n",
      "[iteration 0310] loss: 281.0671\n",
      "[iteration 0320] loss: 281.0671\n",
      "[iteration 0330] loss: 281.0671\n",
      "[iteration 0340] loss: 281.0671\n",
      "[iteration 0350] loss: 281.0671\n",
      "[iteration 0360] loss: 281.0671\n",
      "[iteration 0370] loss: 281.0671\n",
      "[iteration 0380] loss: 281.0671\n",
      "[iteration 0390] loss: 281.0671\n",
      "[iteration 0400] loss: 281.0671\n",
      "[iteration 0410] loss: 281.0671\n",
      "[iteration 0420] loss: 281.0671\n",
      "[iteration 0430] loss: 281.0671\n",
      "[iteration 0440] loss: 281.0671\n",
      "[iteration 0450] loss: 281.0671\n",
      "[iteration 0460] loss: 281.0671\n",
      "[iteration 0470] loss: 281.0671\n",
      "[iteration 0480] loss: 281.0671\n",
      "[iteration 0490] loss: 281.0671\n",
      "[iteration 0500] loss: 281.0671\n",
      "Learned parameters:\n",
      "weight [[0.27673978 0.35073876]]\n",
      "bias [-0.28901267]\n"
     ]
    }
   ],
   "source": [
    "# for CI testing\n",
    "smoke_test = ('CI' in os.environ)\n",
    "pyro.enable_validation(True)\n",
    "pyro.set_rng_seed(1)\n",
    "pyro.enable_validation(True)\n",
    "\n",
    "\n",
    "# setup\n",
    "assert issubclass(PyroModule[nn.Linear], nn.Linear)\n",
    "assert issubclass(PyroModule[nn.Linear], PyroModule)\n",
    "\n",
    "\n",
    "#Data to regress\n",
    "unaware_sample = torch.tensor(unaware_sample)\n",
    "x_data, y_data = unaware_sample[:, :-1], unaware_sample[:, -1]\n",
    "\n",
    "# Regression model\n",
    "# 2 = in features, 1=out feature\n",
    "linear_reg_model = PyroModule[nn.Linear](2, 1)\n",
    "\n",
    "# Define loss and optimize\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "optim = torch.optim.Adam(linear_reg_model.parameters(), lr=0.05)\n",
    "num_iterations = 500 if not smoke_test else 2\n",
    "\n",
    "def train():\n",
    "    # run the model forward on the data\n",
    "    y_pred = linear_reg_model(x_data).squeeze(-1)\n",
    "    # calculate the mse loss\n",
    "    loss = loss_fn(y_pred, y_data)\n",
    "    # initialize gradients to zero\n",
    "    optim.zero_grad()\n",
    "    # backpropagate\n",
    "    loss.backward()\n",
    "    # take a gradient step\n",
    "    optim.step()\n",
    "    return loss\n",
    "\n",
    "for j in range(num_iterations):\n",
    "    loss = train()\n",
    "    if (j + 1) % 10 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss.item()))\n",
    "\n",
    "# Inspect learned parameters\n",
    "print(\"Learned parameters:\")\n",
    "for name, param in linear_reg_model.named_parameters():\n",
    "    print(name, param.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 17.,  45.,  56.,  47.,  38.,  81., 155., 137.,  40.,  14.]),\n",
       " array([-1.743669  , -1.1420765 , -0.5404841 ,  0.06110845,  0.66270095,\n",
       "         1.2642934 ,  1.865886  ,  2.4674785 ,  3.0690708 ,  3.6706634 ,\n",
       "         4.272256  ], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit = samples.copy()\n",
    "fit[\"mean\"] = linear_reg_model(x_data).detach().numpy()\n",
    "\n",
    "S1 = fit[fit[\"S\"] == 1]\n",
    "S0 = fit[fit[\"S\"] == 0]\n",
    "R1 = fit[fit[\"R\"] == 1]\n",
    "R0 = fit[fit[\"R\"] == 0]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6), sharey=True)\n",
    "ax[0].hist(R1[\"mean\"])\n",
    "ax[0].hist(R0[\"mean\"])\n",
    "ax[1].hist(S1[\"mean\"])\n",
    "ax[1].hist(S0[\"mean\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Model\n",
    "\n",
    "This model uses all observable variables. This has the consequence of using R/S directly in its decision. \n",
    "(Causal model here would show R/S causing FYA as well). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "      <th>S</th>\n",
       "      <th>A</th>\n",
       "      <th>G</th>\n",
       "      <th>L</th>\n",
       "      <th>F</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.0739)</td>\n",
       "      <td>tensor(4.8844)</td>\n",
       "      <td>tensor(6.4200)</td>\n",
       "      <td>tensor(3.2143)</td>\n",
       "      <td>tensor(0.0547)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(1.6005)</td>\n",
       "      <td>tensor(3.9457)</td>\n",
       "      <td>tensor(7.4651)</td>\n",
       "      <td>tensor(4.0628)</td>\n",
       "      <td>tensor(0.1327)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(-0.6672)</td>\n",
       "      <td>tensor(1.1866)</td>\n",
       "      <td>tensor(5.1768)</td>\n",
       "      <td>tensor(1.9296)</td>\n",
       "      <td>tensor(0.3032)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(-0.2638)</td>\n",
       "      <td>tensor(2.5346)</td>\n",
       "      <td>tensor(5.3216)</td>\n",
       "      <td>tensor(1.7472)</td>\n",
       "      <td>tensor(0.0176)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(-0.9319)</td>\n",
       "      <td>tensor(1.6503)</td>\n",
       "      <td>tensor(4.8414)</td>\n",
       "      <td>tensor(0.9323)</td>\n",
       "      <td>tensor(0.1051)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            R           S                A               G               L  \\\n",
       "0  tensor(1.)  tensor(1.)   tensor(0.0739)  tensor(4.8844)  tensor(6.4200)   \n",
       "1  tensor(1.)  tensor(0.)   tensor(1.6005)  tensor(3.9457)  tensor(7.4651)   \n",
       "2  tensor(1.)  tensor(0.)  tensor(-0.6672)  tensor(1.1866)  tensor(5.1768)   \n",
       "3  tensor(1.)  tensor(0.)  tensor(-0.2638)  tensor(2.5346)  tensor(5.3216)   \n",
       "4  tensor(1.)  tensor(0.)  tensor(-0.9319)  tensor(1.6503)  tensor(4.8414)   \n",
       "\n",
       "                F               p  \n",
       "0  tensor(3.2143)  tensor(0.0547)  \n",
       "1  tensor(4.0628)  tensor(0.1327)  \n",
       "2  tensor(1.9296)  tensor(0.3032)  \n",
       "3  tensor(1.7472)  tensor(0.0176)  \n",
       "4  tensor(0.9323)  tensor(0.1051)  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = pd.DataFrame(columns=['R', 'S', 'A', 'G', 'L', 'F', 'p'])\n",
    "full_sample= []\n",
    "for i in range(1000):\n",
    "    trace = trace_handler.get_trace(exo_dist)\n",
    "    R = trace.nodes['R']['value']\n",
    "    S = trace.nodes['S']['value']\n",
    "    A = trace.nodes['A']['value']\n",
    "    G = trace.nodes['G']['value']\n",
    "    L = trace.nodes['L']['value']\n",
    "    F = trace.nodes['F']['value']\n",
    "    # get prob of each combination\n",
    "    log_prob = trace.log_prob_sum()\n",
    "    p = np.exp(log_prob)\n",
    "    samples=samples.append({'R': R, 'S': S, 'A': A, 'G': G, 'L':L, 'F': F, 'p': p}, ignore_index=True)\n",
    "    full_sample.append(([R,S,G,L,F]))\n",
    "\n",
    "samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0010] loss: 789.6496\n",
      "[iteration 0020] loss: 971.4789\n",
      "[iteration 0030] loss: 723.6378\n",
      "[iteration 0040] loss: 383.9923\n",
      "[iteration 0050] loss: 370.0474\n",
      "[iteration 0060] loss: 339.2785\n",
      "[iteration 0070] loss: 302.6099\n",
      "[iteration 0080] loss: 278.8698\n",
      "[iteration 0090] loss: 261.9639\n",
      "[iteration 0100] loss: 248.0414\n",
      "[iteration 0110] loss: 236.1470\n",
      "[iteration 0120] loss: 225.9137\n",
      "[iteration 0130] loss: 217.0389\n",
      "[iteration 0140] loss: 209.2750\n",
      "[iteration 0150] loss: 202.4385\n",
      "[iteration 0160] loss: 196.3949\n",
      "[iteration 0170] loss: 191.0415\n",
      "[iteration 0180] loss: 186.2945\n",
      "[iteration 0190] loss: 182.0818\n",
      "[iteration 0200] loss: 178.3382\n",
      "[iteration 0210] loss: 175.0039\n",
      "[iteration 0220] loss: 172.0241\n",
      "[iteration 0230] loss: 169.3489\n",
      "[iteration 0240] loss: 166.9330\n",
      "[iteration 0250] loss: 164.7365\n",
      "[iteration 0260] loss: 162.7241\n",
      "[iteration 0270] loss: 160.8655\n",
      "[iteration 0280] loss: 159.1345\n",
      "[iteration 0290] loss: 157.5092\n",
      "[iteration 0300] loss: 155.9714\n",
      "[iteration 0310] loss: 154.5060\n",
      "[iteration 0320] loss: 153.1007\n",
      "[iteration 0330] loss: 151.7456\n",
      "[iteration 0340] loss: 150.4330\n",
      "[iteration 0350] loss: 149.1566\n",
      "[iteration 0360] loss: 147.9118\n",
      "[iteration 0370] loss: 146.6950\n",
      "[iteration 0380] loss: 145.5035\n",
      "[iteration 0390] loss: 144.3354\n",
      "[iteration 0400] loss: 143.1892\n",
      "[iteration 0410] loss: 142.0640\n",
      "[iteration 0420] loss: 140.9592\n",
      "[iteration 0430] loss: 139.8745\n",
      "[iteration 0440] loss: 138.8097\n",
      "[iteration 0450] loss: 137.7646\n",
      "[iteration 0460] loss: 136.7394\n",
      "[iteration 0470] loss: 135.7341\n",
      "[iteration 0480] loss: 134.7488\n",
      "[iteration 0490] loss: 133.7836\n",
      "[iteration 0500] loss: 132.8387\n",
      "Learned parameters:\n",
      "weight [[-1.8048851  -0.45470715  0.30250278  0.61171335]]\n",
      "bias [-0.04319745]\n"
     ]
    }
   ],
   "source": [
    "#Data to regress\n",
    "full_sample = torch.tensor(full_sample)\n",
    "x_data, y_data = full_sample[:, :-1], full_sample[:, -1]\n",
    "\n",
    "# Regression model\n",
    "# 2 = in features, 1=out feature\n",
    "linear_reg_model = PyroModule[nn.Linear](4, 1)\n",
    "\n",
    "# Define loss and optimize\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "optim = torch.optim.Adam(linear_reg_model.parameters(), lr=0.05)\n",
    "num_iterations = 500 if not smoke_test else 2\n",
    "\n",
    "def train():\n",
    "    # run the model forward on the data\n",
    "    y_pred = linear_reg_model(x_data).squeeze(-1)\n",
    "    # calculate the mse loss\n",
    "    loss = loss_fn(y_pred, y_data)\n",
    "    # initialize gradients to zero\n",
    "    optim.zero_grad()\n",
    "    # backpropagate\n",
    "    loss.backward()\n",
    "    # take a gradient step\n",
    "    optim.step()\n",
    "    return loss\n",
    "\n",
    "for j in range(num_iterations):\n",
    "    loss = train()\n",
    "    if (j + 1) % 10 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss.item()))\n",
    "\n",
    "# Inspect learned parameters\n",
    "print(\"Learned parameters:\")\n",
    "for name, param in linear_reg_model.named_parameters():\n",
    "    print(name, param.data.numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.,  19.,  33.,  65.,  77., 134., 155.,  98.,  45.,   2.]),\n",
       " array([-2.8060572 , -2.0081537 , -1.2102501 , -0.41234654,  0.38555703,\n",
       "         1.1834606 ,  1.9813641 ,  2.7792678 ,  3.5771713 ,  4.375075  ,\n",
       "         5.1729784 ], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit = samples.copy()\n",
    "fit[\"mean\"] = linear_reg_model(x_data).detach().numpy()\n",
    "\n",
    "S1 = fit[fit[\"S\"] == 1]\n",
    "S0 = fit[fit[\"S\"] == 0]\n",
    "R1 = fit[fit[\"R\"] == 1]\n",
    "R0 = fit[fit[\"R\"] == 0]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6), sharey=True)\n",
    "ax[0].hist(R1[\"mean\"])\n",
    "ax[0].hist(R0[\"mean\"])\n",
    "ax[1].hist(S1[\"mean\"])\n",
    "ax[1].hist(S0[\"mean\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferring K\n",
    "\n",
    "This model infers K and uses that to predict FYA instead of relying on R,S (which are parents of G,L making those indirectly biased). First trains on all features (including R and S). Then learns K and uses that to predict F."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "      <th>S</th>\n",
       "      <th>A</th>\n",
       "      <th>G</th>\n",
       "      <th>L</th>\n",
       "      <th>F</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(-0.0342)</td>\n",
       "      <td>tensor(1.9971)</td>\n",
       "      <td>tensor(5.8420)</td>\n",
       "      <td>tensor(2.2940)</td>\n",
       "      <td>tensor(0.5667)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(0.5362)</td>\n",
       "      <td>tensor(3.4626)</td>\n",
       "      <td>tensor(6.2691)</td>\n",
       "      <td>tensor(2.8632)</td>\n",
       "      <td>tensor(0.1350)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.0234)</td>\n",
       "      <td>tensor(3.4050)</td>\n",
       "      <td>tensor(0.8411)</td>\n",
       "      <td>tensor(0.8340)</td>\n",
       "      <td>tensor(0.0717)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(1.6624)</td>\n",
       "      <td>tensor(4.5280)</td>\n",
       "      <td>tensor(7.4667)</td>\n",
       "      <td>tensor(3.5183)</td>\n",
       "      <td>tensor(0.0200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(1.0750)</td>\n",
       "      <td>tensor(6.7196)</td>\n",
       "      <td>tensor(7.6605)</td>\n",
       "      <td>tensor(4.3718)</td>\n",
       "      <td>tensor(0.1429)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            R           S                A               G               L  \\\n",
       "0  tensor(1.)  tensor(0.)  tensor(-0.0342)  tensor(1.9971)  tensor(5.8420)   \n",
       "1  tensor(1.)  tensor(0.)   tensor(0.5362)  tensor(3.4626)  tensor(6.2691)   \n",
       "2  tensor(0.)  tensor(1.)   tensor(0.0234)  tensor(3.4050)  tensor(0.8411)   \n",
       "3  tensor(1.)  tensor(0.)   tensor(1.6624)  tensor(4.5280)  tensor(7.4667)   \n",
       "4  tensor(1.)  tensor(1.)   tensor(1.0750)  tensor(6.7196)  tensor(7.6605)   \n",
       "\n",
       "                F               p  \n",
       "0  tensor(2.2940)  tensor(0.5667)  \n",
       "1  tensor(2.8632)  tensor(0.1350)  \n",
       "2  tensor(0.8340)  tensor(0.0717)  \n",
       "3  tensor(3.5183)  tensor(0.0200)  \n",
       "4  tensor(4.3718)  tensor(0.1429)  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = pd.DataFrame(columns=['R', 'S', 'A', 'G', 'L', 'F', 'p'])\n",
    "aware_sample= []\n",
    "for i in range(1000):\n",
    "    trace = trace_handler.get_trace()\n",
    "    R = trace.nodes['R']['value']\n",
    "    S = trace.nodes['S']['value']\n",
    "    A = trace.nodes['A']['value']\n",
    "    G = trace.nodes['G']['value']\n",
    "    L = trace.nodes['L']['value']\n",
    "    F = trace.nodes['F']['value']\n",
    "    # get prob of each combination\n",
    "    log_prob = trace.log_prob_sum()\n",
    "    p = np.exp(log_prob)\n",
    "    samples = samples.append({'R': R, 'S': S, 'A': A, 'G': G, 'L':L, 'F': F, 'p': p}, ignore_index=True)\n",
    "    aware_sample.append(([R,S,F]))\n",
    "\n",
    "samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the observed G and L\n",
    "G=samples.G\n",
    "L=samples.L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through all the generated samples and use the G/L (observed variables) to infer that sample's K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold all K values\n",
    "K=[]\n",
    "# iterate through the 1000 samples of G/L and infer K\n",
    "for i in range(1000):\n",
    "        conditioned = pyro.condition(model, data={\"G\": G[i], \"L\": L[i]})\n",
    "\n",
    "        # use pyro.infer.Importance\n",
    "        posterior = pyro.infer.Importance(conditioned, num_samples=100).run()\n",
    "        post_marginal = pyro.infer.EmpiricalMarginal(posterior, \"A\")\n",
    "        post_samples = [post_marginal().item() for _ in range(100)]\n",
    "        post_unique, post_counts = np.unique(post_samples, return_counts=True)\n",
    "        # calculate the mean of the inferred\n",
    "        mean = np.mean(post_samples)\n",
    "        K.append(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of the Inferred K and the generated K samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAP+klEQVR4nO3de6xlZX3G8e8jUDVKBcJAJ4AebSdWJXWQUUBsg2IQoRE1QjVGp4hOk6KVaohjbWptYjumaq3WS6dKAYNYqhKwWHGkXGLCbaCI0IFKdIAplBnvUFrN4K9/7DWvh+EwZ8uctde5fD/Jzt7r3e/a67eAmYd3Xd6VqkKSJIDHDV2AJGn+MBQkSY2hIElqDAVJUmMoSJKaPYcuYHfsv//+NTU1NXQZkrSg3HDDDd+rqmUzfbegQ2FqaoqNGzcOXYYkLShJ7ny07zx8JElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoW9B3N0mym1l4y2LY3rztxsG1Lj5UjBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1PQWCkkOSXJ5kk1Jbk3y9q59vyQbkny7e9+3a0+Sjya5I8nNSZ7XV22SpJnt2eNvbwfeWVU3JtkbuCHJBuD3gcuqal2StcBa4F3Ay4EV3esI4JPduxaBqbWXDF2CpDH0NlKoqnur6sbu8/3AJuAg4CTgnK7bOcAru88nAefWyDXAPkmW91WfJOmRJnJOIckUcBhwLXBgVd0Lo+AADui6HQTcPW21LV3bzr+1JsnGJBu3bdvWZ9mStOT0HgpJngx8ETijqn6yq64ztNUjGqrWV9Wqqlq1bNmyuSpTkkTPoZBkL0aBcF5Vfalrvm/HYaHufWvXvgU4ZNrqBwP39FmfJOnh+rz6KMBngE1V9eFpX10MrO4+rwYumtb+xu4qpCOBH+84zCRJmow+rz46GngD8K0kN3VtfwKsAy5IchpwF3By991XgBOAO4AHgVN7rE2SNIPeQqGqvsHM5wkAjp2hfwGn91WPJGl2fY4UpCVtqHszNq87cZDtanFwmgtJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpKa3UEhyVpKtSW6Z1vbnSf4ryU3d64Rp3707yR1Jbk/ysr7qkiQ9uj5HCmcDx8/Q/jdVtbJ7fQUgybOB1wLP6db5RJI9eqxNkjSD3kKhqq4CfjBm95OAz1fVT6vqu8AdwAv6qk2SNLMhzim8NcnN3eGlfbu2g4C7p/XZ0rU9QpI1STYm2bht27a+a5WkJWXSofBJ4NeBlcC9wIe69szQt2b6gapaX1WrqmrVsmXL+qlSkpaoiYZCVd1XVQ9V1c+Bf+AXh4i2AIdM63owcM8ka5MkTTgUkiyftvgqYMeVSRcDr03y+CRPB1YA102yNkkS7NnXDyc5HzgG2D/JFuC9wDFJVjI6NLQZ+AOAqro1yQXAfwDbgdOr6qG+apMkzay3UKiq183Q/Jld9H8/8P6+6pEkzc47miVJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJElNb3c0SxrG1NpLBtnu5nUnDrJdzS1HCpKkZqxQSHL0OG2SpIVt3JHCx8ZskyQtYLs8p5DkKOCFwLIk75j21a8Ce/RZmCRp8mY70fwrwJO7fntPa/8J8Jq+ipIkDWOXoVBVVwJXJjm7qu6cUE2SpIGMe0nq45OsB6amr1NVL+mjKEnSMMYNhX8GPgV8GvAxmZK0SI0bCtur6pO9ViJJGty4l6R+OckfJlmeZL8dr14rkyRN3LgjhdXd+5nT2gp4xtyWI0ka0lihUFVP77sQ9W+oOXEkLRxjhUKSN87UXlXnzm05kqQhjXv46PnTPj8BOBa4ETAUJGkRGffw0dumLyd5CvDZXiqSJA3msU6d/SCwYi4LkSQNb9xzCl9mdLURjCbCexZwQV9FSZKGMe45hQ9O+7wduLOqtvRQjyRpQGMdPuomxruN0Uyp+wI/67MoSdIwxn3y2inAdcDJwCnAtUmcOluSFplxDx+9B3h+VW0FSLIM+Drwhb4KkyRN3rhXHz1uRyB0vv9LrCtJWiDGHSl8NcmlwPnd8u8BX+mnJEnSUGZ7RvNvAAdW1ZlJXg28CAhwNXDeBOqTJE3QbIeAPgLcD1BVX6qqd1TVHzMaJXyk7+IkSZM1WyhMVdXNOzdW1UZGj+aUJC0is4XCE3bx3RPnshBJ0vBmC4Xrk7xl58YkpwE37GrFJGcl2Zrklmlt+yXZkOTb3fu+XXuSfDTJHUluTvK8x7IzkqTdM1sonAGcmuSKJB/qXlcCbwbePsu6ZwPH79S2FrisqlYAl3XLAC9nNMHeCmAN4POgJWkAu7z6qKruA16Y5MXAoV3zJVX1b7P9cFVdlWRqp+aTgGO6z+cAVwDv6trPraoCrkmyT5LlVXXvmPshSZoD4z5P4XLg8jnY3oE7/qKvqnuTHNC1HwTcPa3flq7tEaGQZA2j0QRPfepT56AkSdIO8+Wu5MzQVjO0UVXrq2pVVa1atmxZz2VJ0tIy6VC4L8lygO59x9QZW4BDpvU7GLhnwrVJ0pI36VC4GFjdfV4NXDSt/Y3dVUhHAj/2fIIkTd64cx/90pKcz+ik8v5JtgDvBdYBF3SXtN7FaCpuGN0hfQJwB6NHfZ7aV12SpEfXWyhU1ese5atjZ+hbwOl91SJJGs98OdEsSZoHDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1Ow5dAGSFoeptZcMtu3N604cbNuLjSMFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqBrl5Lclm4H7gIWB7Va1Ksh/wT8AUsBk4pap+OER9krRUDTlSeHFVrayqVd3yWuCyqloBXNYtS5ImaD4dPjoJOKf7fA7wygFrkaQlaahQKOBrSW5IsqZrO7Cq7gXo3g+YacUka5JsTLJx27ZtEypXkpaGoSbEO7qq7klyALAhyW3jrlhV64H1AKtWraq+CpSkpWiQkUJV3dO9bwUuBF4A3JdkOUD3vnWI2iRpKZt4KCR5UpK9d3wGjgNuAS4GVnfdVgMXTbo2SVrqhjh8dCBwYZId2/9cVX01yfXABUlOA+4CTh6gNkla0iYeClX1HeC5M7R/Hzh20vVIkn5hPl2SKkkamKEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEnNULOkLmlTay8ZugRJmpEjBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqluxDdnzQjSQ9kiMFSVKzZEcKkhaPoUb+m9edOMh2++RIQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSmnl381qS44G/BfYAPl1V6wYuSZJmNOR0OX3dODevRgpJ9gA+DrwceDbwuiTPHrYqSVo65lUoAC8A7qiq71TVz4DPAycNXJMkLRnz7fDRQcDd05a3AEdM75BkDbCmW3wgye0Tqq0v+wPfG7qIOeY+LQyLcZ9gce7XI/YpH9it33vao30x30IhM7TVwxaq1gPrJ1NO/5JsrKpVQ9cxl9ynhWEx7hMszv2a5D7Nt8NHW4BDpi0fDNwzUC2StOTMt1C4HliR5OlJfgV4LXDxwDVJ0pIxrw4fVdX2JG8FLmV0SepZVXXrwGX1bdEcCpvGfVoYFuM+weLcr4ntU6pq9l6SpCVhvh0+kiQNyFCQJDWGwjyQ5K+T3Jbk5iQXJtln6Jp2V5KTk9ya5OdJFvTlgUmOT3J7kjuSrB26nt2V5KwkW5PcMnQtcyXJIUkuT7Kp++/u7UPXtLuSPCHJdUm+2e3T+yaxXUNhftgAHFpVvwX8J/DugeuZC7cArwauGrqQ3bFIp145Gzh+6CLm2HbgnVX1LOBI4PRF8O/pp8BLquq5wErg+CRH9r1RQ2EeqKqvVdX2bvEaRvdnLGhVtamqFvrd5rAIp16pqquAHwxdx1yqqnur6sbu8/3AJkYzJCxYNfJAt7hX9+r9yiBDYf55E/CvQxehZqapVxb0XzaLXZIp4DDg2mEr2X1J9khyE7AV2FBVve/TvLpPYTFL8nXg12b46j1VdVHX5z2MhsHnTbK2x2qcfVoEZp16RfNHkicDXwTOqKqfDF3P7qqqh4CV3XnGC5McWlW9ngsyFCakql66q++TrAZ+Fzi2FsjNI7Pt0yLh1CsLRJK9GAXCeVX1paHrmUtV9aMkVzA6F9RrKHj4aB7oHiz0LuAVVfXg0PXoYZx6ZQFIEuAzwKaq+vDQ9cyFJMt2XImY5InAS4Hb+t6uoTA//B2wN7AhyU1JPjV0QbsryauSbAGOAi5JcunQNT0W3QUAO6Ze2QRcsNCnXklyPnA18MwkW5KcNnRNc+Bo4A3AS7o/QzclOWHoonbTcuDyJDcz+p+TDVX1L31v1GkuJEmNIwVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaClqwkD4zR57e7GSpv6q4V77OeqZlmLt25PclbktyYZN8+69HSZChIu/Z64INVtbKq/ne2zhl53E5te8xVMUneALwNOK6qfjhXvyvtYChoyUtyTJIrknyhe67Fed1f7m8GTgH+LMl5Xd8zk1zfPfvifV3bVDeP/yeAG4FDkjyQ5C+SXAscleTwJFcmuSHJpUmWd+se3s2XfzVw+ix1ngKsZRQI3+vvn4iWMkNBGjkMOIPRMxOeARxdVZ9mNKXFmVX1+iTHASsYTae9Ejg8ye906z8TOLeqDquqO4EnAbdU1RGMZuv8GPCaqjocOAt4f7fePwJ/VFVHzVLf0xjd+X5cVf333Oyy9EiGgjRyXVVtqaqfAzcBUzP0Oa57/TujEcFvMgoJgDur6pppfR9iNDkbjALjULppTIA/BQ5O8hRgn6q6suv32V3Utw24i9HIReqNs6RKIz+d9vkhZv6zEeCvqurvH9Y4mr//f3bq+3/dtMc71rt159FAN9nZuPPMPMjo6W/fSLK1qhbE9OpaeBwpSOO7FHhTN2c/SQ5KcsAY690OLEtyVLfeXkmeU1U/An6c5EVdv9fv6keqahujqZP/MsnLHvNeSLtgKEhjqqqvAZ8Drk7yLeALjGa3nW29nwGvAT6Q5JuMDk+9sPv6VODj3YnmWa9uqqrvAq8AzkpyxGPaEWkXnCVVktQ4UpAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLU/D8oQNy8m6wfjgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(K)\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Inferred K\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([float(a) for a in samples.A])\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"From calculated samples K\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison between some of the rows: \n",
    "\n",
    "You can see how closely the inferred K's managed to be to the \"actual\" K's (which we technically can never know)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1725) tensor(2.0282) tensor(1.2714) 1.1047669649124146\n",
      "tensor(0.6776) tensor(4.7277) tensor(-1.0685) -1.0126692789793015\n",
      "tensor(1.1278) tensor(4.6387) tensor(-1.1928) -1.1516192603111266\n",
      "tensor(2.0109) tensor(5.6828) tensor(-0.1505) -0.14025823023170234\n"
     ]
    }
   ],
   "source": [
    "for i in range(5, 15, 3):\n",
    "    print(samples.G[i], samples.L[i], samples.A[i], K[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now use our new inferred K into the Linear Reg Model to predict F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [1 x 1000], m2: [1 x 1] at ..\\aten\\src\\TH/generic/THTensorMath.cpp:41",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-156-e109153e99b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[iteration %04d] loss: %.4f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-156-e109153e99b6>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# run the model forward on the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_reg_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;31m# calculate the mse loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyro\\nn\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pyro_context\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1674\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1675\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1676\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1677\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1678\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, m1: [1 x 1000], m2: [1 x 1] at ..\\aten\\src\\TH/generic/THTensorMath.cpp:41"
     ]
    }
   ],
   "source": [
    "#Data to regress\n",
    "# convert numpy.float64 types to float, then to tensor\n",
    "x_data, y_data = torch.tensor(np.array(K).tolist()), torch.tensor(samples.F)\n",
    "\n",
    "# Regression model\n",
    "linear_reg_model = PyroModule[nn.Linear](1, 1)\n",
    "\n",
    "# Define loss and optimize\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "optim = torch.optim.Adam(linear_reg_model.parameters(), lr=0.05)\n",
    "num_iterations = 500 \n",
    "\n",
    "def train():\n",
    "    # run the model forward on the data\n",
    "    y_pred = linear_reg_model(x_data).squeeze(-1)\n",
    "    # calculate the mse loss\n",
    "    loss = loss_fn(y_pred, y_data)\n",
    "    # initialize gradients to zero\n",
    "    optim.zero_grad()\n",
    "    # backpropagate\n",
    "    loss.backward()\n",
    "    # take a gradient step\n",
    "    optim.step()\n",
    "    return loss\n",
    "\n",
    "for j in range(num_iterations):\n",
    "    loss = train()\n",
    "    if (j + 1) % 10 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss.item()))\n",
    "\n",
    "# Inspect learned parameters\n",
    "print(\"Learned parameters:\")\n",
    "for name, param in linear_reg_model.named_parameters():\n",
    "    print(name, param.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([461.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 193.]),\n",
       " array([0.4549464 , 0.45644417, 0.45794195, 0.45943975, 0.46093753,\n",
       "        0.4624353 , 0.46393308, 0.46543086, 0.46692866, 0.46842644,\n",
       "        0.4699242 ], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit = samples.copy()\n",
    "fit[\"mean\"] = linear_reg_model(A_pred).detach().numpy()\n",
    "\n",
    "S1 = fit[fit[\"S\"] == 1]\n",
    "S0 = fit[fit[\"S\"] == 0]\n",
    "R1 = fit[fit[\"R\"] == 1]\n",
    "R0 = fit[fit[\"R\"] == 0]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6), sharey=True)\n",
    "ax[0].hist(R1[\"mean\"])\n",
    "ax[0].hist(R0[\"mean\"])\n",
    "ax[1].hist(S1[\"mean\"])\n",
    "ax[1].hist(S0[\"mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
