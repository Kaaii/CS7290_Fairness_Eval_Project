{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from torch import nn\n",
    "from pyro.nn import PyroModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "exo_dist = {\n",
    "    'Nr': dist.Bernoulli(torch.tensor(0.7)),\n",
    "    'Ns': dist.Bernoulli(torch.tensor(0.35)),\n",
    "    'Na': dist.Normal(torch.tensor(0.), torch.tensor(1.))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(exo_dist):\n",
    "    # sample from bernoulli 0 or 1, 0 at 70% freq (made up)\n",
    "    R = pyro.sample(\"R\", exo_dist['Nr'])\n",
    "    S = pyro.sample(\"S\", exo_dist['Ns'])\n",
    "    \n",
    "    # random gaussian dist for ability \n",
    "    A = pyro.sample(\"A\", exo_dist['Na'])\n",
    "    \n",
    "    \n",
    "    G = pyro.sample(\"G\", dist.Normal(A + 2.1 * R + 3.3 * S, 0.5))\n",
    "    \n",
    "    L = pyro.sample(\"L\", dist.Normal(A + 5.8*R + 0.7*S, 0.1))\n",
    "    \n",
    "    F = pyro.sample(\"F\", dist.Normal(A + 2.3*R + 1.*S, 0.3))\n",
    "\n",
    "trace_handler = pyro.poutine.trace(model)\n",
    "samples = pd.DataFrame(columns=['R', 'S', 'A', 'G', 'L', 'F', 'p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "      <th>S</th>\n",
       "      <th>A</th>\n",
       "      <th>G</th>\n",
       "      <th>L</th>\n",
       "      <th>F</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(1.7664)</td>\n",
       "      <td>tensor(7.8902)</td>\n",
       "      <td>tensor(8.1267)</td>\n",
       "      <td>tensor(5.0909)</td>\n",
       "      <td>tensor(0.0115)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(-0.1765)</td>\n",
       "      <td>tensor(1.8700)</td>\n",
       "      <td>tensor(5.7514)</td>\n",
       "      <td>tensor(1.8165)</td>\n",
       "      <td>tensor(0.1966)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(-0.1683)</td>\n",
       "      <td>tensor(2.3153)</td>\n",
       "      <td>tensor(5.7864)</td>\n",
       "      <td>tensor(1.5196)</td>\n",
       "      <td>tensor(0.0213)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(0.0701)</td>\n",
       "      <td>tensor(2.1746)</td>\n",
       "      <td>tensor(5.9460)</td>\n",
       "      <td>tensor(2.9814)</td>\n",
       "      <td>tensor(0.0721)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>tensor(1.9601)</td>\n",
       "      <td>tensor(2.5712)</td>\n",
       "      <td>tensor(7.7678)</td>\n",
       "      <td>tensor(4.5696)</td>\n",
       "      <td>tensor(0.0008)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            R           S                A               G               L  \\\n",
       "0  tensor(1.)  tensor(1.)   tensor(1.7664)  tensor(7.8902)  tensor(8.1267)   \n",
       "1  tensor(1.)  tensor(0.)  tensor(-0.1765)  tensor(1.8700)  tensor(5.7514)   \n",
       "2  tensor(1.)  tensor(0.)  tensor(-0.1683)  tensor(2.3153)  tensor(5.7864)   \n",
       "3  tensor(1.)  tensor(0.)   tensor(0.0701)  tensor(2.1746)  tensor(5.9460)   \n",
       "4  tensor(1.)  tensor(0.)   tensor(1.9601)  tensor(2.5712)  tensor(7.7678)   \n",
       "\n",
       "                F               p  \n",
       "0  tensor(5.0909)  tensor(0.0115)  \n",
       "1  tensor(1.8165)  tensor(0.1966)  \n",
       "2  tensor(1.5196)  tensor(0.0213)  \n",
       "3  tensor(2.9814)  tensor(0.0721)  \n",
       "4  tensor(4.5696)  tensor(0.0008)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unaware_sample= []\n",
    "for i in range(1000):\n",
    "    trace = trace_handler.get_trace(exo_dist)\n",
    "    R = trace.nodes['R']['value']\n",
    "    S = trace.nodes['S']['value']\n",
    "    A = trace.nodes['A']['value']\n",
    "    G = trace.nodes['G']['value']\n",
    "    L = trace.nodes['L']['value']\n",
    "    F = trace.nodes['F']['value']\n",
    "    # get prob of each combination\n",
    "    log_prob = trace.log_prob_sum()\n",
    "    p = np.exp(log_prob)\n",
    "    samples = samples.append({'R': R, 'S': S, 'A': A, 'G': G, 'L':L, 'F': F, 'p': p}, ignore_index=True)\n",
    "    unaware_sample.append(([G,R,F]))\n",
    "\n",
    "samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0010] loss: 895.8986\n",
      "[iteration 0020] loss: 736.0276\n",
      "[iteration 0030] loss: 691.6636\n",
      "[iteration 0040] loss: 593.6221\n",
      "[iteration 0050] loss: 551.6503\n",
      "[iteration 0060] loss: 529.8733\n",
      "[iteration 0070] loss: 513.1815\n",
      "[iteration 0080] loss: 501.3436\n",
      "[iteration 0090] loss: 493.8453\n",
      "[iteration 0100] loss: 489.4159\n",
      "[iteration 0110] loss: 486.9283\n",
      "[iteration 0120] loss: 485.5989\n",
      "[iteration 0130] loss: 484.9284\n",
      "[iteration 0140] loss: 484.6121\n",
      "[iteration 0150] loss: 484.4734\n",
      "[iteration 0160] loss: 484.4172\n",
      "[iteration 0170] loss: 484.3965\n",
      "[iteration 0180] loss: 484.3898\n",
      "[iteration 0190] loss: 484.3878\n",
      "[iteration 0200] loss: 484.3874\n",
      "[iteration 0210] loss: 484.3874\n",
      "[iteration 0220] loss: 484.3874\n",
      "[iteration 0230] loss: 484.3875\n",
      "[iteration 0240] loss: 484.3874\n",
      "[iteration 0250] loss: 484.3874\n",
      "[iteration 0260] loss: 484.3874\n",
      "[iteration 0270] loss: 484.3874\n",
      "[iteration 0280] loss: 484.3874\n",
      "[iteration 0290] loss: 484.3874\n",
      "[iteration 0300] loss: 484.3874\n",
      "[iteration 0310] loss: 484.3874\n",
      "[iteration 0320] loss: 484.3874\n",
      "[iteration 0330] loss: 484.3875\n",
      "[iteration 0340] loss: 484.3874\n",
      "[iteration 0350] loss: 484.3874\n",
      "[iteration 0360] loss: 484.3874\n",
      "[iteration 0370] loss: 484.3874\n",
      "[iteration 0380] loss: 484.3874\n",
      "[iteration 0390] loss: 484.3874\n",
      "[iteration 0400] loss: 484.3874\n",
      "[iteration 0410] loss: 484.3874\n",
      "[iteration 0420] loss: 484.3874\n",
      "[iteration 0430] loss: 484.3874\n",
      "[iteration 0440] loss: 484.3874\n",
      "[iteration 0450] loss: 484.3874\n",
      "[iteration 0460] loss: 484.3874\n",
      "[iteration 0470] loss: 484.3874\n",
      "[iteration 0480] loss: 484.3874\n",
      "[iteration 0490] loss: 484.3874\n",
      "[iteration 0500] loss: 484.3874\n",
      "Learned parameters:\n",
      "weight [[0.4628451 1.3100717]]\n",
      "bias [-0.16720389]\n"
     ]
    }
   ],
   "source": [
    "# for CI testing\n",
    "smoke_test = ('CI' in os.environ)\n",
    "pyro.enable_validation(True)\n",
    "pyro.set_rng_seed(1)\n",
    "pyro.enable_validation(True)\n",
    "\n",
    "\n",
    "# setup\n",
    "assert issubclass(PyroModule[nn.Linear], nn.Linear)\n",
    "assert issubclass(PyroModule[nn.Linear], PyroModule)\n",
    "\n",
    "\n",
    "#Data to regress\n",
    "unaware_sample = torch.tensor(unaware_sample)\n",
    "x_data, y_data = unaware_sample[:, :-1], unaware_sample[:, -1]\n",
    "\n",
    "# Regression model\n",
    "# 2 = in features, 1=out feature\n",
    "linear_reg_model = PyroModule[nn.Linear](2, 1)\n",
    "\n",
    "# Define loss and optimize\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "optim = torch.optim.Adam(linear_reg_model.parameters(), lr=0.05)\n",
    "num_iterations = 500 if not smoke_test else 2\n",
    "\n",
    "def train():\n",
    "    # run the model forward on the data\n",
    "    y_pred = linear_reg_model(x_data).squeeze(-1)\n",
    "    # calculate the mse loss\n",
    "    loss = loss_fn(y_pred, y_data)\n",
    "    # initialize gradients to zero\n",
    "    optim.zero_grad()\n",
    "    # backpropagate\n",
    "    loss.backward()\n",
    "    # take a gradient step\n",
    "    optim.step()\n",
    "    return loss\n",
    "\n",
    "for j in range(num_iterations):\n",
    "    loss = train()\n",
    "    if (j + 1) % 10 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss.item()))\n",
    "\n",
    "# Inspect learned parameters\n",
    "print(\"Learned parameters:\")\n",
    "for name, param in linear_reg_model.named_parameters():\n",
    "    print(name, param.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 13.,  44.,  88.,  48.,  30., 108., 186., 111.,  13.,   4.]),\n",
       " array([-1.606006  , -1.0300199 , -0.45403376,  0.12195238,  0.6979385 ,\n",
       "         1.2739246 ,  1.8499107 ,  2.425897  ,  3.001883  ,  3.5778692 ,\n",
       "         4.1538553 ], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit = samples.copy()\n",
    "fit[\"mean\"] = linear_reg_model(x_data).detach().numpy()\n",
    "\n",
    "S1 = fit[fit[\"S\"] == 1]\n",
    "S0 = fit[fit[\"S\"] == 0]\n",
    "R1 = fit[fit[\"R\"] == 1]\n",
    "R0 = fit[fit[\"R\"] == 0]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6), sharey=True)\n",
    "ax[0].hist(R1[\"mean\"])\n",
    "ax[0].hist(R0[\"mean\"])\n",
    "ax[1].hist(S1[\"mean\"])\n",
    "ax[1].hist(S0[\"mean\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
